{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU') #本地需要这样操作\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu ,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "x_train_path=glob.glob('./dataset/dc_2000/train/*/*.jpg')\n",
    "x_test_path=glob.glob('./dataset/dc_2000/test/*/*.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "2000"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 88
    }
   ],
   "source": [
    "len(x_train_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "#cat 0\n",
    "#dog 1\n",
    "y_train=[int(p.split('\\\\')[1]=='dog') for p in x_train_path]\n",
    "y_test=[int(p.split('\\\\')[1]=='dog') for p in x_test_path]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_preprosess_image(img_path):\n",
    "    img_raw=tf.io.read_file(img_path)   \n",
    "    img_tensor=tf.image.decode_jpeg(img_raw,channels=3)\n",
    "    #普通方法\n",
    "\t#img_tensor=tf.image.resize(img_tensor,[256,256])\n",
    "    #数据增强\n",
    "    img_tensor=tf.image.resize(img_tensor,[360,360])\n",
    "    img_tensor=tf.image.random_crop(img_tensor,[256,256,3])#随机裁剪\n",
    "    img_tensor=tf.image.random_flip_left_right(img_tensor) #随机左右翻转\n",
    "    img_tensor=tf.image.random_flip_up_down(img_tensor) #随机上下翻转\n",
    "    #下面的效果不明显\n",
    "    #img_tensor=tf.image.random_brightness(img_tensor,0.5) #随机改变亮度\n",
    "    #img_tensor=tf.image.random_contrast(img_tensor,0,1) #随机对比度\n",
    "    #img_tensor=tf.image.random_hue(img_tensor,0.3) #随机颜色\n",
    "    #img_tensor=tf.image.random_saturation(img_tensor,0.2,1.8)#随机饱和度\n",
    "    ##\n",
    "    \n",
    "    img_tensor=tf.cast(img_tensor,tf.float32)\n",
    "    img_tensor=img_tensor/255\n",
    "    return img_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def load_preprosess_image_test(img_path):\n",
    "    img_raw=tf.io.read_file(img_path)   \n",
    "    img_tensor=tf.image.decode_jpeg(img_raw,channels=3)\n",
    "    img_tensor=tf.image.resize(img_tensor,[256,256])\n",
    "    img_tensor=tf.cast(img_tensor,tf.float32)\n",
    "    img_tensor=img_tensor/255\n",
    "    return img_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#label : [1, 2, 3]==>[ [1], [2], [3]]\n",
    "y_train=tf.reshape(y_train,[-1,1]) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "#自动并行运行\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "train_path_dataset=tf.data.Dataset.from_tensor_slices(x_train_path)\n",
    "x_train_dataset=train_path_dataset.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)\n",
    "y_train_dataset=tf.data.Dataset.from_tensor_slices(y_train)\n",
    "dataset_train=tf.data.Dataset.zip((x_train_dataset,y_train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "test_path_dataset=tf.data.Dataset.from_tensor_slices(x_test_path)\n",
    "x_test_dataset=test_path_dataset.map(load_preprosess_image_test,num_parallel_calls=AUTOTUNE)\n",
    "y_test_dataset=tf.data.Dataset.from_tensor_slices(y_test)\n",
    "dataset_test=tf.data.Dataset.zip((x_test_dataset,y_test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "train_count=len(x_train_path)\n",
    "dataset_train=dataset_train.shuffle(train_count).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "#prefetch是预加载\n",
    "dataset_test=dataset_test.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(64,(3,3),input_shape=(256,256,3),activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(512,(3,3),activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512,(3,3),activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(256,activation='relu'),\n",
    "        tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 254, 254, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 60, 60, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,682,561\n",
      "Trainable params: 1,682,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "x,y=next(iter(dataset_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "pred=model.predict(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(32,), dtype=int32, numpy=\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 100
    }
   ],
   "source": [
    "tf.reshape(tf.cast(pred>0,tf.int32),[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(32,), dtype=int32, numpy=\narray([1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n       1, 1, 1, 0, 0, 0, 0, 1, 1, 0])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 101
    }
   ],
   "source": [
    "tf.reshape(y,[-1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "epoch_loss_avg_train=tf.keras.metrics.Mean('train_loss')\n",
    "train_accuracy=tf.keras.metrics.Accuracy()\n",
    "epoch_loss_avg_test=tf.keras.metrics.Mean('test_loss')\n",
    "test_accuracy=tf.keras.metrics.Accuracy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#自定义训练保存模型\n",
    "##cp_dir='./customtrain_cp'\n",
    "##cp_prefix='./customtrain_cp/ckpt'\n",
    "##checkpoint=tf.train.Checkpoint(optimizer=optimizer, model=model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def train_step(model,x_train,y_train):\n",
    "    with tf.GradientTape() as t:\n",
    "        y_pred=model(x_train) #写成model.predict就不可以训练了\n",
    "        loss_step=tf.keras.losses.BinaryCrossentropy()(y_train,y_pred)\n",
    "    \n",
    "    grads=t.gradient(loss_step,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    epoch_loss_avg_train(loss_step)\n",
    "    train_accuracy(y_train,tf.cast(y_pred>0.5,tf.int32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "train_loss_res=[]\n",
    "train_acc_loss=[]\n",
    "test_loss_res=[]\n",
    "test_acc_loss=[]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def test_step(model,x_test,y_test):\n",
    "    y_pred=model.predict(x_test) #model(x_test,training=False)\n",
    "    loss_step=tf.keras.losses.BinaryCrossentropy()(y_test,y_pred)\n",
    "    epoch_loss_avg_test(loss_step)\n",
    "    test_accuracy(y_test,tf.cast(y_pred>0.5,tf.int32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "epochs=30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        for x,y in dataset_train:\n",
    "            train_step(model,x,y)\n",
    "            print('.',end='')\n",
    "        print()\n",
    "        train_loss_res.append(epoch_loss_avg_train.result())\n",
    "        train_acc_loss.append(train_accuracy.result())\n",
    "        \n",
    "        for x,y in dataset_test:\n",
    "            test_step(model,x,y)\n",
    "        train_loss_res.append(epoch_loss_avg_test.result())\n",
    "        train_acc_loss.append(test_accuracy.result())\n",
    "        template = 'Epoch{}, loss: {:.3f}, acc: {:.3f} , test_loss: {}, test_acc: {}'\n",
    "        print(\n",
    "            template.format(\n",
    "                epoch+1,\n",
    "                epoch_loss_avg_train.result(),\n",
    "                train_accuracy.result(),\n",
    "                epoch_loss_avg_test.result(),\n",
    "                test_accuracy.result(),\n",
    "            )\n",
    "        )\n",
    "        epoch_loss_avg_train.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        epoch_loss_avg_test.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "        #保存检查点 ，每两步保存一次 \n",
    "        ##if(epoch+1)%2==0:\n",
    "        ##   checkpoint.save(file_prefix=cp_prefix )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "...............................................................\n",
      "Epoch1, loss: 0.694, acc: 0.493 , test_loss: 0.6895403861999512, test_acc: 0.5\n",
      "...............................................................\n",
      "Epoch2, loss: 0.694, acc: 0.506 , test_loss: 0.6935567855834961, test_acc: 0.5\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "#恢复检查点\n",
    "##checkpoint.restore(tf.train.latest_checkpoint(cp_dir))\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tfenv",
   "language": "python",
   "display_name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}